{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the template for DS3000 Final data analysis project. Once you finish, please remove all my instructions. You do not need to exactly follow the structure in the template but please make sure you have all the components. Write your report in paragraphs. Only use bullet points when list something (eg: functions) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS3000 Final Project \n",
    "#### Team number: 9\n",
    "- Xavier Yu, Vilasini Nathan, Justin Lee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pylab as py\n",
    "import scipy.stats as stats\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdunction\n",
    "\n",
    "- One or two paragraphs about the background of the project. eg: the backgound of PalWorld and why your analysis can be interesting\n",
    "- State your research questions. Limit the number of research questions to be one or two. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data \n",
    "\n",
    "### Data Source\n",
    "\n",
    "- List the website you have scraped the data from.\n",
    "- List which information you have scraped\n",
    "- Describe what kind of cleaning you have done to the data\n",
    "\n",
    "### Webscraping and cleaning functions overview\n",
    "\n",
    "List all the functions you have written for webscraping and data cleaning. For each one, write one sentence to describe it. \n",
    "- `extract_soup()`\n",
    "    - build url and return soup object\n",
    "\n",
    "### Data overview\n",
    "\n",
    "- Show a couple of rows of the cleaned data you are going to use for the analysis\n",
    "- Which is your target value (if exists)\n",
    "- Give a general summary about the other features\n",
    "- Discuss if there is any potential problems about the data (eg: missing values, any features that you did not collect but may be important, any other concerns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the functions you have for webscraping and cleaning. Make sure write full \n",
    "# docstrings for each function\n",
    "def extract_soup():\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_html(url):\n",
    "    \"\"\"\n",
    "    Retrieve HTML content from a given URL\n",
    "\n",
    "    Args:\n",
    "        url (str): The webpage URL to fetch HTML from\n",
    "\n",
    "    Returns:\n",
    "        str: HTML content as a string.\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pal_links(html):\n",
    "    \"\"\"\n",
    "    Extracts and returns a list of links to pals from the HTML soup object.\n",
    "    \n",
    "    Args:\n",
    "        html (string): html text of a webpage\n",
    "        \n",
    "    Returns:\n",
    "        pal_links (list): A list of full URLs to individual pal pages.\n",
    "    \"\"\"\n",
    "    # parse HTML content to create soup\n",
    "    soup = BeautifulSoup(html)\n",
    "    \n",
    "    pal_links = []  # Create an empty list to store full URLs\n",
    "\n",
    "    # Find all <div> elements with class pal\n",
    "    for pal_div in soup.find_all('div', class_='pal'):\n",
    "        \n",
    "        # Inside each <div class='pal'>, find the first <a> tag\n",
    "        a_tag = pal_div.find('a')\n",
    "        \n",
    "        # Check if the <a> tag exists and has an 'href' attribute\n",
    "        if a_tag and a_tag.has_attr('href'):\n",
    "            # Build the full link by appending the relative path to the base URL\n",
    "            full_link = 'https://palworld.gg' + a_tag['href']\n",
    "            pal_links.append(full_link)\n",
    "\n",
    "    return pal_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_pal_data(pal_links):\n",
    "    \"\"\"\n",
    "    Given a list of Palworld page links, fetch each page and extract the pal's name and stats.\n",
    "\n",
    "    Args:\n",
    "        pal_links (list): A list of full URLs to individual pal pages.\n",
    "\n",
    "    Returns:\n",
    "        pal_data (dictionary): dictionary containing a pal's name, link, and stats.\n",
    "    \"\"\"    \n",
    "    name, href, stats = [], [], []\n",
    "\n",
    "    for link in pal_links:\n",
    "        # Request the HTML content of each pal's page\n",
    "        response = requests.get(link)\n",
    "        if response.status_code != 200:\n",
    "            continue\n",
    "\n",
    "        # Parse the HTML using BeautifulSoup\n",
    "        pal_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Get the pal's name from the <h1> tag\n",
    "        name_tag = pal_soup.find('h1')\n",
    "        pal_name = name_tag.text.strip() if name_tag else 'Unknown'\n",
    "\n",
    "        # Dictionary to store stats like HP, Attack, etc.\n",
    "        stats_dict = {}\n",
    "\n",
    "        # Look for the section containing stats\n",
    "        stats_div = pal_soup.find('div', class_='stats')\n",
    "        if stats_div:\n",
    "            items_div = stats_div.find('div', class_='items')\n",
    "            if items_div:\n",
    "                # Loop through all stat items\n",
    "                for item in items_div.find_all('div', class_='item'):\n",
    "                    stat_name_tag = item.find('div', class_='name')\n",
    "                    stat_value_tag = item.find('div', class_='value')\n",
    "                    if stat_name_tag and stat_value_tag:\n",
    "                        stat_name = stat_name_tag.text.strip()\n",
    "                        stat_value = stat_value_tag.text.strip()\n",
    "                        stats_dict[stat_name] = stat_value\n",
    "\n",
    "        # Save the collected data into corresponding lists\n",
    "        name.append(pal_name)\n",
    "        href.append(link)\n",
    "        stats.append(stats_dict)\n",
    "        \n",
    "    pal_data = {'Name': name, 'Link': href, 'Stats': stats}\n",
    "\n",
    "\n",
    "    return pal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rarity_info(pal_data):\n",
    "    \"\"\"\n",
    "    Adds rarity_level and rarity_name to each pal dictionary\n",
    "    \n",
    "    Args:\n",
    "        pal_data (dictionary): contains pal info with at least a 'Link' key.\n",
    "        \n",
    "    Returns:\n",
    "        pal_data (dictionary): 'Rarity Level' and 'Rarity Name' fields added\n",
    "    \"\"\"\n",
    "    # empty lists to store rarity level and rarity name\n",
    "    rar_level, rar_name = [], []\n",
    "    \n",
    "    for link in pal_data['Link']:\n",
    "        html = get_html(link)  # FIXED: now using each Pal's page\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "        # Find the rarity div\n",
    "        rarity_div = soup.find('div', class_='rarity')\n",
    "        rarity_level, rarity_name = None, None\n",
    "        if rarity_div:\n",
    "            lv_tag = rarity_div.find('div', class_='lv')\n",
    "            name_tag = rarity_div.find('div', class_='name')\n",
    "            if lv_tag and name_tag:\n",
    "                rarity_level = lv_tag.text.strip()\n",
    "                rarity_name = name_tag.text.strip()\n",
    "\n",
    "        rar_level.append(rarity_level)\n",
    "        rar_name.append(rarity_name)\n",
    "        \n",
    "    pal_data['Rarity Level'] = rar_level\n",
    "    pal_data['Rarity Name'] = rar_name\n",
    "\n",
    "    return pal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_element_work(pal_data):\n",
    "    \"\"\"\n",
    "    Adds element and work suitability to pal_data\n",
    "    \n",
    "    Args:\n",
    "        pal_data (dictionary): Dictionary, with at least a 'Link' key.\n",
    "        \n",
    "    Returns:\n",
    "        pal_data (dictionary): 'Element', 'Work Suitability' added\n",
    "    \n",
    "    \"\"\"\n",
    "    # empty lists to store element and work suitability\n",
    "    element, work = [], []\n",
    "    \n",
    "    # iterate through all links\n",
    "    for link in pal_data['Link']:\n",
    "        \n",
    "        # get HTML\n",
    "        html = get_html(link)\n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(html)\n",
    "        \n",
    "        # to store all elements of each pal\n",
    "        pal_element = []\n",
    "        \n",
    "        # get contents of first div with class elements\n",
    "        elements_div = soup.find('div', class_='elements')\n",
    "\n",
    "        # get text from each element and append to pal_element\n",
    "        for el in elements_div.find_all('div', class_='name'):\n",
    "                    element_text = el.text.strip()\n",
    "                    pal_element.append(element_text)\n",
    "        \n",
    "        # empty dict to store work suitability and level\n",
    "        work_level = {}\n",
    "\n",
    "        # get contents of first div with class works\n",
    "        works_div = soup.find('div', class_='works')\n",
    "\n",
    "        # iterates through contents of work_div with div and class item\n",
    "        for item in works_div.find_all('div', class_='item'):\n",
    "            \n",
    "            # only extracts displayed items\n",
    "            if 'display:none' not in item.get('style', ''):\n",
    "                if 'Lv' in item.text:\n",
    "                    work_suit, level = item.text.split('Lv')\n",
    "                    work_level[work_suit] = int(level)\n",
    "                else:\n",
    "                    work_suit = item.text.strip()\n",
    "                    work_level[work_suit] = ''\n",
    "        \n",
    "        # appends pal_element and work_level to the larger element and work lists\n",
    "        element.append(pal_element)\n",
    "        work.append(work_level)\n",
    "    \n",
    "    # adds to dictionary\n",
    "    pal_data['Element'] = element\n",
    "    pal_data['Work Suitability'] = work\n",
    "    \n",
    "    return pal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://palworld.gg/pals'\n",
    "html = get_html(url)\n",
    "pal_links = extract_pal_links(html)\n",
    "\n",
    "pal_data = fetch_pal_data(pal_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal_data = add_rarity_info(pal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal_data = add_element_work(pal_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Link</th>\n",
       "      <th>Stats</th>\n",
       "      <th>Rarity Level</th>\n",
       "      <th>Rarity Name</th>\n",
       "      <th>Element</th>\n",
       "      <th>Work Suitability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anubis</td>\n",
       "      <td>https://palworld.gg/pal/anubis</td>\n",
       "      <td>{'HP': '120', 'Defense': '100', 'Crafting Spee...</td>\n",
       "      <td>10</td>\n",
       "      <td>Epic</td>\n",
       "      <td>[Earth]</td>\n",
       "      <td>{'Handiwork': 4, 'Mining': 3, 'Transporting': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arsox</td>\n",
       "      <td>https://palworld.gg/pal/arsox</td>\n",
       "      <td>{'HP': '85', 'Defense': '95', 'Crafting Speed'...</td>\n",
       "      <td>4</td>\n",
       "      <td>Common</td>\n",
       "      <td>[Fire]</td>\n",
       "      <td>{'Deforesting': 1, 'Kindling': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Astegon</td>\n",
       "      <td>https://palworld.gg/pal/astegon</td>\n",
       "      <td>{'HP': '100', 'Defense': '125', 'Crafting Spee...</td>\n",
       "      <td>9</td>\n",
       "      <td>Epic</td>\n",
       "      <td>[Dragon, Dark]</td>\n",
       "      <td>{'Handiwork': 1, 'Mining': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Azurmane</td>\n",
       "      <td>https://palworld.gg/pal/azurmane</td>\n",
       "      <td>{'HP': '130', 'Defense': '110', 'Crafting Spee...</td>\n",
       "      <td>7</td>\n",
       "      <td>Rare</td>\n",
       "      <td>[Electricity]</td>\n",
       "      <td>{'Gathering': 1, 'Generating Electricity': 4}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Azurobe</td>\n",
       "      <td>https://palworld.gg/pal/azurobe</td>\n",
       "      <td>{'HP': '110', 'Defense': '100', 'Crafting Spee...</td>\n",
       "      <td>7</td>\n",
       "      <td>Rare</td>\n",
       "      <td>[Water, Dragon]</td>\n",
       "      <td>{'Watering': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Wumpo Botan</td>\n",
       "      <td>https://palworld.gg/pal/wumpo-botan</td>\n",
       "      <td>{'HP': '140', 'Defense': '110', 'Crafting Spee...</td>\n",
       "      <td>8</td>\n",
       "      <td>Epic</td>\n",
       "      <td>[Leaf]</td>\n",
       "      <td>{'Deforesting': 3, 'Handiwork': 2, 'Planting':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>Xenogard</td>\n",
       "      <td>https://palworld.gg/pal/xenogard</td>\n",
       "      <td>{'HP': '110', 'Defense': '130', 'Crafting Spee...</td>\n",
       "      <td>9</td>\n",
       "      <td>Epic</td>\n",
       "      <td>[Dragon]</td>\n",
       "      <td>{'Mining': 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>Xenolord</td>\n",
       "      <td>https://palworld.gg/pal/xenolord</td>\n",
       "      <td>{'HP': '130', 'Defense': '120', 'Crafting Spee...</td>\n",
       "      <td>8</td>\n",
       "      <td>Epic</td>\n",
       "      <td>[Dark, Dragon]</td>\n",
       "      <td>{'Gathering': 1}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Xenovader</td>\n",
       "      <td>https://palworld.gg/pal/xenovader</td>\n",
       "      <td>{'HP': '90', 'Defense': '85', 'Crafting Speed'...</td>\n",
       "      <td>7</td>\n",
       "      <td>Rare</td>\n",
       "      <td>[Dark]</td>\n",
       "      <td>{'Deforesting': 2, 'Transporting': 2}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>Yakumo</td>\n",
       "      <td>https://palworld.gg/pal/yakumo</td>\n",
       "      <td>{'HP': '85', 'Defense': '85', 'Crafting Speed'...</td>\n",
       "      <td>4</td>\n",
       "      <td>Common</td>\n",
       "      <td>[Normal]</td>\n",
       "      <td>{'Gathering': 2}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Name                                 Link  \\\n",
       "0         Anubis       https://palworld.gg/pal/anubis   \n",
       "1          Arsox        https://palworld.gg/pal/arsox   \n",
       "2        Astegon      https://palworld.gg/pal/astegon   \n",
       "3       Azurmane     https://palworld.gg/pal/azurmane   \n",
       "4        Azurobe      https://palworld.gg/pal/azurobe   \n",
       "..           ...                                  ...   \n",
       "220  Wumpo Botan  https://palworld.gg/pal/wumpo-botan   \n",
       "221     Xenogard     https://palworld.gg/pal/xenogard   \n",
       "222     Xenolord     https://palworld.gg/pal/xenolord   \n",
       "223    Xenovader    https://palworld.gg/pal/xenovader   \n",
       "224       Yakumo       https://palworld.gg/pal/yakumo   \n",
       "\n",
       "                                                 Stats Rarity Level  \\\n",
       "0    {'HP': '120', 'Defense': '100', 'Crafting Spee...           10   \n",
       "1    {'HP': '85', 'Defense': '95', 'Crafting Speed'...            4   \n",
       "2    {'HP': '100', 'Defense': '125', 'Crafting Spee...            9   \n",
       "3    {'HP': '130', 'Defense': '110', 'Crafting Spee...            7   \n",
       "4    {'HP': '110', 'Defense': '100', 'Crafting Spee...            7   \n",
       "..                                                 ...          ...   \n",
       "220  {'HP': '140', 'Defense': '110', 'Crafting Spee...            8   \n",
       "221  {'HP': '110', 'Defense': '130', 'Crafting Spee...            9   \n",
       "222  {'HP': '130', 'Defense': '120', 'Crafting Spee...            8   \n",
       "223  {'HP': '90', 'Defense': '85', 'Crafting Speed'...            7   \n",
       "224  {'HP': '85', 'Defense': '85', 'Crafting Speed'...            4   \n",
       "\n",
       "    Rarity Name          Element  \\\n",
       "0          Epic          [Earth]   \n",
       "1        Common           [Fire]   \n",
       "2          Epic   [Dragon, Dark]   \n",
       "3          Rare    [Electricity]   \n",
       "4          Rare  [Water, Dragon]   \n",
       "..          ...              ...   \n",
       "220        Epic           [Leaf]   \n",
       "221        Epic         [Dragon]   \n",
       "222        Epic   [Dark, Dragon]   \n",
       "223        Rare           [Dark]   \n",
       "224      Common         [Normal]   \n",
       "\n",
       "                                      Work Suitability  \n",
       "0     {'Handiwork': 4, 'Mining': 3, 'Transporting': 2}  \n",
       "1                    {'Deforesting': 1, 'Kindling': 2}  \n",
       "2                        {'Handiwork': 1, 'Mining': 4}  \n",
       "3        {'Gathering': 1, 'Generating Electricity': 4}  \n",
       "4                                      {'Watering': 3}  \n",
       "..                                                 ...  \n",
       "220  {'Deforesting': 3, 'Handiwork': 2, 'Planting':...  \n",
       "221                                      {'Mining': 3}  \n",
       "222                                   {'Gathering': 1}  \n",
       "223              {'Deforesting': 2, 'Transporting': 2}  \n",
       "224                                   {'Gathering': 2}  \n",
       "\n",
       "[225 rows x 7 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(pal_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations\n",
    "\n",
    "### Visualization functions overview\n",
    "List all the functions you have written for visualization. For each one, write one sentence to describe it. \n",
    "- `make_hist()`\n",
    "    - Generate a histogram with given data and feature\n",
    " \n",
    "### Visualization results\n",
    "- Present 3-4 data visualizations.\n",
    "- For each visualization, you need to include title, xlabel, ylabel, legend (if necessary)\n",
    "- For each visualization, explain why you make this data visualization (how it related to your research question) and explain what you have learned from this visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the functions you have for visualization. Make sure write full \n",
    "# docstrings for each function\n",
    "def make_hist(df, y_feat):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to get each data visualization in separate code chunks. \n",
    "# Interpret the figures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to get each data visualization in separate code chunks. \n",
    "# Interpret the figures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### visualization 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to get each data visualization in separate code chunks. \n",
    "# Interpret the figures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "### Modeling functions overview\n",
    "List all the functions you have written for modeling. For each one, write one sentence to describe it. \n",
    "- `fit_linear()`\n",
    "    - fit a linear model to the data and output the r2, slope and intercept\n",
    "\n",
    "### Model results\n",
    "\n",
    "- Present 2-3 models for the analysis.\n",
    "- Explain any pre-processing steps you have done (eg: scaling, polynomial, dummy features)\n",
    "- For each model, explain why you think this model is suitable and what metrics you want to use to evaluate the model\n",
    "    - If it is a classification model, you need to present the confusion matrix, calculate the accuracy, sensitivity and specificity with cross-validation\n",
    "    - If it is a regression model, you need to present the r2 and MSE with cross-validation\n",
    "    - If it is a linear regression model/multiple linear regression model, you need to interpret the meaning of the coefficient with the full data\n",
    "    - If it is a decision tree model, you need to plot the tree with the full data\n",
    "    - If it is a random forest model, you need to present the feature importance plot with the full data\n",
    "    - If it is a PCA, you need to explain how to select the number of components and interpret the key features in the first two components\n",
    "    - If it is a clustering, you need explain how to select the number of clustering and summarize the clustering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all the functions you have for modeling. Make sure write full \n",
    "# docstrings for each function\n",
    "def fit_linear(df, y_feat, x_feat):\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to fit each model in separate code chunks. \n",
    "# Interpret the model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to fit each model in separate code chunks. \n",
    "# Interpret the model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the code to run functions to fit each model in separate code chunks. \n",
    "# Interpret the model results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "- One or two paragraphs to summarize your findings in the modeling sections and do the models answer your research question?\r",
    "- Any other potential thing you can do with the analysis (eg: include more features, get more data, try some other models etc.)\n",
    "- List the contribution for each group member."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
